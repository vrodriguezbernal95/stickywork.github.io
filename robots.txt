# robots.txt para StickyWork
# https://vrodriguezbernal95.github.io/stickywork.github.io/

User-agent: *
Allow: /

# Páginas principales - Alta prioridad
Allow: /index.html
Allow: /como-funciona.html
Allow: /planes.html
Allow: /demo.html
Allow: /contacto.html

# Assets públicos
Allow: /css/
Allow: /js/
Allow: /images/
Allow: /public/

# Bloqueardirectorios privados
Disallow: /admin/
Disallow: /admin-login.html
Disallow: /admin-dashboard.html
Disallow: /admin-mensajes.html
Disallow: /backend/
Disallow: /node_modules/
Disallow: /config/
Disallow: /.git/
Disallow: /.env

# Archivos técnicos
Disallow: /package.json
Disallow: /package-lock.json
Disallow: /*.md$

# Archivos temporales y de prueba
Disallow: /test-*.html
Disallow: /ejemplo*.html
Disallow: /*test*.html

# URLs con parámetros de sesión
Disallow: /*?sessionid=
Disallow: /*?token=

# Sitemap
Sitemap: https://vrodriguezbernal95.github.io/stickywork.github.io/sitemap.xml

# Crawl delay (opcional - solo si hay problemas de carga)
# Crawl-delay: 1

# Bots específicos
User-agent: Googlebot
Allow: /

User-agent: Googlebot-Image
Allow: /images/

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Bloquear bots maliciosos
User-agent: AhrefsBot
Crawl-delay: 10

User-agent: MJ12bot
Crawl-delay: 10

User-agent: SemrushBot
Crawl-delay: 10
